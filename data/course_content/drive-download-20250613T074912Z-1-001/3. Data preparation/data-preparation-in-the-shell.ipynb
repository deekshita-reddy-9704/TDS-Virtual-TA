{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOKRUJMNjhk0fu4rU8eN/jv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Data preparation in the shell\n","\n","UNIX has a great set of tools to clean and analyze data.\n","\n","This is important because [these tools are](https://jeroenjanssens.com/dsatcl/chapter-1-introduction#why-data-science-at-the-command-line):\n","\n","- **Agile**: You can quickly explore data and see the results.\n","- **Fast**: They're written in C. They're easily parallelizable.\n","- **Popular**: Most systems and languages support shell commands.\n","\n","In this notebook, we'll explore log files with these shell-based commands."],"metadata":{"id":"e-ELl5tGVX66"}},{"cell_type":"markdown","source":["## Download logs\n","\n","[This file](https://drive.google.com/file/d/1J1ed4iHFAiS1Xq55aP858OEyEMQ-uMnE/view) has Apache web server logs for the site [s-anand.net](https://s-anand.net/) in the month of April 2024.\n","\n","You can download files using `wget` or `curl`. One of these is usually available by default on most systems.\n","\n","We'll use `curl` to download the file from the URL `https://drive.usercontent.google.com/uc?id=1J1ed4iHFAiS1Xq55aP858OEyEMQ-uMnE&export=download`"],"metadata":{"id":"nddebjgnXivF"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O2vkjPNCU7g2","executionInfo":{"status":"ok","timestamp":1717910332278,"user_tz":-540,"elapsed":542,"user":{"displayName":"Anand S","userId":"10615265647738071129"}},"outputId":"939a192b-e907-437c-d535-3b35ad4f1109"},"outputs":[{"output_type":"stream","name":"stdout","text":["Usage: curl [options...] <url>\n","     --abstract-unix-socket <path> Connect via abstract Unix domain socket\n","     --alt-svc <file name> Enable alt-svc with this cache file\n","     --anyauth            Pick any authentication method\n"," -a, --append             Append to target file when uploading\n","     --aws-sigv4 <provider1[:provider2[:region[:service]]]> Use AWS V4 signature authentication\n","     --basic              Use HTTP Basic Authentication\n","     --cacert <file>      CA certificate to verify peer against\n","     --capath <dir>       CA directory to verify peer against\n"," -E, --cert <certificate[:password]> Client certificate file and password\n","     --cert-status        Verify the status of the server cert via OCSP-staple\n","     --cert-type <type>   Certificate type (DER/PEM/ENG)\n","     --ciphers <list of ciphers> SSL ciphers to use\n","     --compressed         Request compressed response\n","     --compressed-ssh     Enable SSH compression\n"," -K, --config <file>      Read config from a file\n","     --connect-timeout <fractional seconds> Maximum time allowed for connection\n","     --connect-to <HOST1:PORT1:HOST2:PORT2> Connect to host\n"," -C, --continue-at <offset> Resumed transfer offset\n"," -b, --cookie <data|filename> Send cookies from string/file\n"," -c, --cookie-jar <filename> Write cookies to <filename> after operation\n","     --create-dirs        Create necessary local directory hierarchy\n","     --create-file-mode <mode> File mode for created files\n","     --crlf               Convert LF to CRLF in upload\n","     --crlfile <file>     Use this CRL list\n","     --curves <algorithm list> (EC) TLS key exchange algorithm(s) to request\n"," -d, --data <data>        HTTP POST data\n","     --data-ascii <data>  HTTP POST ASCII data\n","     --data-binary <data> HTTP POST binary data\n","     --data-raw <data>    HTTP POST data, '@' allowed\n","     --data-urlencode <data> HTTP POST data url encoded\n","     --delegation <LEVEL> GSS-API delegation permission\n","     --digest             Use HTTP Digest Authentication\n"," -q, --disable            Disable .curlrc\n","     --disable-eprt       Inhibit using EPRT or LPRT\n","     --disable-epsv       Inhibit using EPSV\n","     --disallow-username-in-url Disallow username in url\n","     --dns-interface <interface> Interface to use for DNS requests\n","     --dns-ipv4-addr <address> IPv4 address to use for DNS requests\n","     --dns-ipv6-addr <address> IPv6 address to use for DNS requests\n","     --dns-servers <addresses> DNS server addrs to use\n","     --doh-cert-status    Verify the status of the DoH server cert via OCSP-staple\n","     --doh-insecure       Allow insecure DoH server connections\n","     --doh-url <URL>      Resolve host names over DoH\n"," -D, --dump-header <filename> Write the received headers to <filename>\n","     --egd-file <file>    EGD socket path for random data\n","     --engine <name>      Crypto engine to use\n","     --etag-compare <file> Pass an ETag from a file as a custom header\n","     --etag-save <file>   Parse ETag from a request and save it to a file\n","     --expect100-timeout <seconds> How long to wait for 100-continue\n"," -f, --fail               Fail silently (no output at all) on HTTP errors\n","     --fail-early         Fail on first transfer error, do not continue\n","     --fail-with-body     Fail on HTTP errors but save the body\n","     --false-start        Enable TLS False Start\n"," -F, --form <name=content> Specify multipart MIME data\n","     --form-escape        Escape multipart form field/file names using backslash\n","     --form-string <name=string> Specify multipart MIME data\n","     --ftp-account <data> Account data string\n","     --ftp-alternative-to-user <command> String to replace USER [name]\n","     --ftp-create-dirs    Create the remote dirs if not present\n","     --ftp-method <method> Control CWD usage\n","     --ftp-pasv           Use PASV/EPSV instead of PORT\n"," -P, --ftp-port <address> Use PORT instead of PASV\n","     --ftp-pret           Send PRET before PASV\n","     --ftp-skip-pasv-ip   Skip the IP address for PASV\n","     --ftp-ssl-ccc        Send CCC after authenticating\n","     --ftp-ssl-ccc-mode <active/passive> Set CCC mode\n","     --ftp-ssl-control    Require SSL/TLS for FTP login, clear for transfer\n"," -G, --get                Put the post data in the URL and use GET\n"," -g, --globoff            Disable URL sequences and ranges using {} and []\n","     --happy-eyeballs-timeout-ms <milliseconds> Time for IPv6 before trying IPv4\n","     --haproxy-protocol   Send HAProxy PROXY protocol v1 header\n"," -I, --head               Show document info only\n"," -H, --header <header/@file> Pass custom header(s) to server\n"," -h, --help <category>    Get help for commands\n","     --hostpubmd5 <md5>   Acceptable MD5 hash of the host public key\n","     --hostpubsha256 <sha256> Acceptable SHA256 hash of the host public key\n","     --hsts <file name>   Enable HSTS with this cache file\n","     --http0.9            Allow HTTP 0.9 responses\n"," -0, --http1.0            Use HTTP 1.0\n","     --http1.1            Use HTTP 1.1\n","     --http2              Use HTTP 2\n","     --http2-prior-knowledge Use HTTP 2 without HTTP/1.1 Upgrade\n","     --http3              Use HTTP v3\n","     --ignore-content-length Ignore the size of the remote resource\n"," -i, --include            Include protocol response headers in the output\n"," -k, --insecure           Allow insecure server connections\n","     --interface <name>   Use network INTERFACE (or address)\n"," -4, --ipv4               Resolve names to IPv4 addresses\n"," -6, --ipv6               Resolve names to IPv6 addresses\n"," -j, --junk-session-cookies Ignore session cookies read from file\n","     --keepalive-time <seconds> Interval time for keepalive probes\n","     --key <key>          Private key file name\n","     --key-type <type>    Private key file type (DER/PEM/ENG)\n","     --krb <level>        Enable Kerberos with security <level>\n","     --libcurl <file>     Dump libcurl equivalent code of this command line\n","     --limit-rate <speed> Limit transfer speed to RATE\n"," -l, --list-only          List only mode\n","     --local-port <num/range> Force use of RANGE for local port numbers\n"," -L, --location           Follow redirects\n","     --location-trusted   Like --location, and send auth to other hosts\n","     --login-options <options> Server login options\n","     --mail-auth <address> Originator address of the original email\n","     --mail-from <address> Mail from this address\n","     --mail-rcpt <address> Mail to this address\n","     --mail-rcpt-allowfails Allow RCPT TO command to fail for some recipients\n"," -M, --manual             Display the full manual\n","     --max-filesize <bytes> Maximum file size to download\n","     --max-redirs <num>   Maximum number of redirects allowed\n"," -m, --max-time <fractional seconds> Maximum time allowed for transfer\n","     --metalink           Process given URLs as metalink XML file\n","     --negotiate          Use HTTP Negotiate (SPNEGO) authentication\n"," -n, --netrc              Must read .netrc for user name and password\n","     --netrc-file <filename> Specify FILE for netrc\n","     --netrc-optional     Use either .netrc or URL\n"," -:, --next               Make next URL use its separate set of options\n","     --no-alpn            Disable the ALPN TLS extension\n"," -N, --no-buffer          Disable buffering of the output stream\n","     --no-keepalive       Disable TCP keepalive on the connection\n","     --no-npn             Disable the NPN TLS extension\n","     --no-progress-meter  Do not show the progress meter\n","     --no-sessionid       Disable SSL session-ID reusing\n","     --noproxy <no-proxy-list> List of hosts which do not use proxy\n","     --ntlm               Use HTTP NTLM authentication\n","     --ntlm-wb            Use HTTP NTLM authentication with winbind\n","     --oauth2-bearer <token> OAuth 2 Bearer Token\n"," -o, --output <file>      Write to file instead of stdout\n","     --output-dir <dir>   Directory to save files in\n"," -Z, --parallel           Perform transfers in parallel\n","     --parallel-immediate Do not wait for multiplexing (with --parallel)\n","     --parallel-max <num> Maximum concurrency for parallel transfers\n","     --pass <phrase>      Pass phrase for the private key\n","     --path-as-is         Do not squash .. sequences in URL path\n","     --pinnedpubkey <hashes> FILE/HASHES Public key to verify peer against\n","     --post301            Do not switch to GET after following a 301\n","     --post302            Do not switch to GET after following a 302\n","     --post303            Do not switch to GET after following a 303\n","     --preproxy [protocol://]host[:port] Use this proxy first\n"," -#, --progress-bar       Display transfer progress as a bar\n","     --proto <protocols>  Enable/disable PROTOCOLS\n","     --proto-default <protocol> Use PROTOCOL for any URL missing a scheme\n","     --proto-redir <protocols> Enable/disable PROTOCOLS on redirect\n"," -x, --proxy [protocol://]host[:port] Use this proxy\n","     --proxy-anyauth      Pick any proxy authentication method\n","     --proxy-basic        Use Basic authentication on the proxy\n","     --proxy-cacert <file> CA certificate to verify peer against for proxy\n","     --proxy-capath <dir> CA directory to verify peer against for proxy\n","     --proxy-cert <cert[:passwd]> Set client certificate for proxy\n","     --proxy-cert-type <type> Client certificate type for HTTPS proxy\n","     --proxy-ciphers <list> SSL ciphers to use for proxy\n","     --proxy-crlfile <file> Set a CRL list for proxy\n","     --proxy-digest       Use Digest authentication on the proxy\n","     --proxy-header <header/@file> Pass custom header(s) to proxy\n","     --proxy-insecure     Do HTTPS proxy connections without verifying the proxy\n","     --proxy-key <key>    Private key for HTTPS proxy\n","     --proxy-key-type <type> Private key file type for proxy\n","     --proxy-negotiate    Use HTTP Negotiate (SPNEGO) authentication on the proxy\n","     --proxy-ntlm         Use NTLM authentication on the proxy\n","     --proxy-pass <phrase> Pass phrase for the private key for HTTPS proxy\n","     --proxy-pinnedpubkey <hashes> FILE/HASHES public key to verify proxy with\n","     --proxy-service-name <name> SPNEGO proxy service name\n","     --proxy-ssl-allow-beast Allow security flaw for interop for HTTPS proxy\n","     --proxy-ssl-auto-client-cert Use auto client certificate for proxy (Schannel)\n","     --proxy-tls13-ciphers <ciphersuite list> TLS 1.3 proxy cipher suites\n","     --proxy-tlsauthtype <type> TLS authentication type for HTTPS proxy\n","     --proxy-tlspassword <string> TLS password for HTTPS proxy\n","     --proxy-tlsuser <name> TLS username for HTTPS proxy\n","     --proxy-tlsv1        Use TLSv1 for HTTPS proxy\n"," -U, --proxy-user <user:password> Proxy user and password\n","     --proxy1.0 <host[:port]> Use HTTP/1.0 proxy on given port\n"," -p, --proxytunnel        Operate through an HTTP proxy tunnel (using CONNECT)\n","     --pubkey <key>       SSH Public key file name\n"," -Q, --quote <command>    Send command(s) to server before transfer\n","     --random-file <file> File for reading random data from\n"," -r, --range <range>      Retrieve only the bytes within RANGE\n","     --raw                Do HTTP \"raw\"; no transfer decoding\n"," -e, --referer <URL>      Referrer URL\n"," -J, --remote-header-name Use the header-provided filename\n"," -O, --remote-name        Write output to a file named as the remote file\n","     --remote-name-all    Use the remote file name for all URLs\n"," -R, --remote-time        Set the remote file's time on the local output\n"," -X, --request <method>   Specify request method to use\n","     --request-target <path> Specify the target for this request\n","     --resolve <[+]host:port:addr[,addr]...> Resolve the host+port to this address\n","     --retry <num>        Retry request if transient problems occur\n","     --retry-all-errors   Retry all errors (use with --retry)\n","     --retry-connrefused  Retry on connection refused (use with --retry)\n","     --retry-delay <seconds> Wait time between retries\n","     --retry-max-time <seconds> Retry only within this period\n","     --sasl-authzid <identity> Identity for SASL PLAIN authentication\n","     --sasl-ir            Enable initial response in SASL authentication\n","     --service-name <name> SPNEGO service name\n"," -S, --show-error         Show error even when -s is used\n"," -s, --silent             Silent mode\n","     --socks4 <host[:port]> SOCKS4 proxy on given host + port\n","     --socks4a <host[:port]> SOCKS4a proxy on given host + port\n","     --socks5 <host[:port]> SOCKS5 proxy on given host + port\n","     --socks5-basic       Enable username/password auth for SOCKS5 proxies\n","     --socks5-gssapi      Enable GSS-API auth for SOCKS5 proxies\n","     --socks5-gssapi-nec  Compatibility with NEC SOCKS5 server\n","     --socks5-gssapi-service <name> SOCKS5 proxy service name for GSS-API\n","     --socks5-hostname <host[:port]> SOCKS5 proxy, pass host name to proxy\n"," -Y, --speed-limit <speed> Stop transfers slower than this\n"," -y, --speed-time <seconds> Trigger 'speed-limit' abort after this time\n","     --ssl                Try SSL/TLS\n","     --ssl-allow-beast    Allow security flaw to improve interop\n","     --ssl-auto-client-cert Use auto client certificate (Schannel)\n","     --ssl-no-revoke      Disable cert revocation checks (Schannel)\n","     --ssl-reqd           Require SSL/TLS\n","     --ssl-revoke-best-effort Ignore missing/offline cert CRL dist points\n"," -2, --sslv2              Use SSLv2\n"," -3, --sslv3              Use SSLv3\n","     --stderr <file>      Where to redirect stderr\n","     --styled-output      Enable styled output for HTTP headers\n","     --suppress-connect-headers Suppress proxy CONNECT response headers\n","     --tcp-fastopen       Use TCP Fast Open\n","     --tcp-nodelay        Use the TCP_NODELAY option\n"," -t, --telnet-option <opt=val> Set telnet option\n","     --tftp-blksize <value> Set TFTP BLKSIZE option\n","     --tftp-no-options    Do not send any TFTP options\n"," -z, --time-cond <time>   Transfer based on a time condition\n","     --tls-max <VERSION>  Set maximum allowed TLS version\n","     --tls13-ciphers <ciphersuite list> TLS 1.3 cipher suites to use\n","     --tlsauthtype <type> TLS authentication type\n","     --tlspassword <string> TLS password\n","     --tlsuser <name>     TLS user name\n"," -1, --tlsv1              Use TLSv1.0 or greater\n","     --tlsv1.0            Use TLSv1.0 or greater\n","     --tlsv1.1            Use TLSv1.1 or greater\n","     --tlsv1.2            Use TLSv1.2 or greater\n","     --tlsv1.3            Use TLSv1.3 or greater\n","     --tr-encoding        Request compressed transfer encoding\n","     --trace <file>       Write a debug trace to FILE\n","     --trace-ascii <file> Like --trace, but without hex output\n","     --trace-time         Add time stamps to trace/verbose output\n","     --unix-socket <path> Connect through this Unix domain socket\n"," -T, --upload-file <file> Transfer local FILE to destination\n","     --url <url>          URL to work with\n"," -B, --use-ascii          Use ASCII/text transfer\n"," -u, --user <user:password> Server user and password\n"," -A, --user-agent <name>  Send User-Agent <name> to server\n"," -v, --verbose            Make the operation more talkative\n"," -V, --version            Show version number and quit\n"," -w, --write-out <format> Use output FORMAT after completion\n","     --xattr              Store metadata in extended file attributes\n"]}],"source":["# curl has LOTs of options. You won't remember most, but it's fun to geek out.\n","!curl --help all"]},{"cell_type":"code","source":["# We're using 3 curl options here:\n","#   --continue-at - continues the download from where it left off. It won't download if already downloaded\n","#   --location downloads the file even if the link sends us somewhere else\n","#   --output FILE saves the downloaded output as\n","!curl --continue-at - \\\n","  --location \\\n","  --output s-anand.net-Apr-2024.gz \\\n","  https://drive.usercontent.google.com/uc?id=1J1ed4iHFAiS1Xq55aP858OEyEMQ-uMnE&export=download"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_PWOwi7sYmuT","executionInfo":{"status":"ok","timestamp":1717910334593,"user_tz":-540,"elapsed":1824,"user":{"displayName":"Anand S","userId":"10615265647738071129"}},"outputId":"eb42cf4e-600e-4701-f847-63963463312c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n","100 5665k  100 5665k    0     0  3139k      0  0:00:01  0:00:01 --:--:-- 9602k\n"]}]},{"cell_type":"markdown","source":["## List files\n","\n","`ls` lists files. It too has lots of options."],"metadata":{"id":"l9VQ_-oF6Qmi"}},{"cell_type":"code","source":["!ls --help"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Olzq3-xf6Wfi","executionInfo":{"status":"ok","timestamp":1717910334593,"user_tz":-540,"elapsed":12,"user":{"displayName":"Anand S","userId":"10615265647738071129"}},"outputId":"9a53c3a6-15e3-4bd9-f6fd-c7b615b4e486"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Usage: ls [OPTION]... [FILE]...\n","List information about the FILEs (the current directory by default).\n","Sort entries alphabetically if none of -cftuvSUX nor --sort is specified.\n","\n","Mandatory arguments to long options are mandatory for short options too.\n","  -a, --all                  do not ignore entries starting with .\n","  -A, --almost-all           do not list implied . and ..\n","      --author               with -l, print the author of each file\n","  -b, --escape               print C-style escapes for nongraphic characters\n","      --block-size=SIZE      with -l, scale sizes by SIZE when printing them;\n","                               e.g., '--block-size=M'; see SIZE format below\n","  -B, --ignore-backups       do not list implied entries ending with ~\n","  -c                         with -lt: sort by, and show, ctime (time of last\n","                               modification of file status information);\n","                               with -l: show ctime and sort by name;\n","                               otherwise: sort by ctime, newest first\n","  -C                         list entries by columns\n","      --color[=WHEN]         colorize the output; WHEN can be 'always' (default\n","                               if omitted), 'auto', or 'never'; more info below\n","  -d, --directory            list directories themselves, not their contents\n","  -D, --dired                generate output designed for Emacs' dired mode\n","  -f                         do not sort, enable -aU, disable -ls --color\n","  -F, --classify             append indicator (one of */=>@|) to entries\n","      --file-type            likewise, except do not append '*'\n","      --format=WORD          across -x, commas -m, horizontal -x, long -l,\n","                               single-column -1, verbose -l, vertical -C\n","      --full-time            like -l --time-style=full-iso\n","  -g                         like -l, but do not list owner\n","      --group-directories-first\n","                             group directories before files;\n","                               can be augmented with a --sort option, but any\n","                               use of --sort=none (-U) disables grouping\n","  -G, --no-group             in a long listing, don't print group names\n","  -h, --human-readable       with -l and -s, print sizes like 1K 234M 2G etc.\n","      --si                   likewise, but use powers of 1000 not 1024\n","  -H, --dereference-command-line\n","                             follow symbolic links listed on the command line\n","      --dereference-command-line-symlink-to-dir\n","                             follow each command line symbolic link\n","                               that points to a directory\n","      --hide=PATTERN         do not list implied entries matching shell PATTERN\n","                               (overridden by -a or -A)\n","      --hyperlink[=WHEN]     hyperlink file names; WHEN can be 'always'\n","                               (default if omitted), 'auto', or 'never'\n","      --indicator-style=WORD  append indicator with style WORD to entry names:\n","                               none (default), slash (-p),\n","                               file-type (--file-type), classify (-F)\n","  -i, --inode                print the index number of each file\n","  -I, --ignore=PATTERN       do not list implied entries matching shell PATTERN\n","  -k, --kibibytes            default to 1024-byte blocks for disk usage;\n","                               used only with -s and per directory totals\n","  -l                         use a long listing format\n","  -L, --dereference          when showing file information for a symbolic\n","                               link, show information for the file the link\n","                               references rather than for the link itself\n","  -m                         fill width with a comma separated list of entries\n","  -n, --numeric-uid-gid      like -l, but list numeric user and group IDs\n","  -N, --literal              print entry names without quoting\n","  -o                         like -l, but do not list group information\n","  -p, --indicator-style=slash\n","                             append / indicator to directories\n","  -q, --hide-control-chars   print ? instead of nongraphic characters\n","      --show-control-chars   show nongraphic characters as-is (the default,\n","                               unless program is 'ls' and output is a terminal)\n","  -Q, --quote-name           enclose entry names in double quotes\n","      --quoting-style=WORD   use quoting style WORD for entry names:\n","                               literal, locale, shell, shell-always,\n","                               shell-escape, shell-escape-always, c, escape\n","                               (overrides QUOTING_STYLE environment variable)\n","  -r, --reverse              reverse order while sorting\n","  -R, --recursive            list subdirectories recursively\n","  -s, --size                 print the allocated size of each file, in blocks\n","  -S                         sort by file size, largest first\n","      --sort=WORD            sort by WORD instead of name: none (-U), size (-S),\n","                               time (-t), version (-v), extension (-X)\n","      --time=WORD            change the default of using modification times;\n","                               access time (-u): atime, access, use;\n","                               change time (-c): ctime, status;\n","                               birth time: birth, creation;\n","                             with -l, WORD determines which time to show;\n","                             with --sort=time, sort by WORD (newest first)\n","      --time-style=TIME_STYLE  time/date format with -l; see TIME_STYLE below\n","  -t                         sort by time, newest first; see --time\n","  -T, --tabsize=COLS         assume tab stops at each COLS instead of 8\n","  -u                         with -lt: sort by, and show, access time;\n","                               with -l: show access time and sort by name;\n","                               otherwise: sort by access time, newest first\n","  -U                         do not sort; list entries in directory order\n","  -v                         natural sort of (version) numbers within text\n","  -w, --width=COLS           set output width to COLS.  0 means no limit\n","  -x                         list entries by lines instead of by columns\n","  -X                         sort alphabetically by entry extension\n","  -Z, --context              print any security context of each file\n","  -1                         list one file per line.  Avoid '\\n' with -q or -b\n","      --help     display this help and exit\n","      --version  output version information and exit\n","\n","The SIZE argument is an integer and optional unit (example: 10K is 10*1024).\n","Units are K,M,G,T,P,E,Z,Y (powers of 1024) or KB,MB,... (powers of 1000).\n","Binary prefixes can be used, too: KiB=K, MiB=M, and so on.\n","\n","The TIME_STYLE argument can be full-iso, long-iso, iso, locale, or +FORMAT.\n","FORMAT is interpreted like in date(1).  If FORMAT is FORMAT1<newline>FORMAT2,\n","then FORMAT1 applies to non-recent files and FORMAT2 to recent files.\n","TIME_STYLE prefixed with 'posix-' takes effect only outside the POSIX locale.\n","Also the TIME_STYLE environment variable sets the default style to use.\n","\n","Using color to distinguish file types is disabled both by default and\n","with --color=never.  With --color=auto, ls emits color codes only when\n","standard output is connected to a terminal.  The LS_COLORS environment\n","variable can change the settings.  Use the dircolors command to set it.\n","\n","Exit status:\n"," 0  if OK,\n"," 1  if minor problems (e.g., cannot access subdirectory),\n"," 2  if serious trouble (e.g., cannot access command-line argument).\n","\n","GNU coreutils online help: <https://www.gnu.org/software/coreutils/>\n","Full documentation <https://www.gnu.org/software/coreutils/ls>\n","or available locally via: info '(coreutils) ls invocation'\n"]}]},{"cell_type":"code","source":["# By default, it just lists all file names\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oTnB6dgh5N8K","executionInfo":{"status":"ok","timestamp":1717910334594,"user_tz":-540,"elapsed":9,"user":{"displayName":"Anand S","userId":"10615265647738071129"}},"outputId":"8c106215-0065-4b73-adb1-91b302370589"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["sample_data  s-anand.net-Apr-2024.gz\n"]}]},{"cell_type":"code","source":["# If we want to see the size of the file, use `-l` for the long-listing format\n","!ls -l"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"372D6Om06fJ0","executionInfo":{"status":"ok","timestamp":1717910335114,"user_tz":-540,"elapsed":525,"user":{"displayName":"Anand S","userId":"10615265647738071129"}},"outputId":"f29641e0-7646-4cd8-efdc-c1695cbea433"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["total 5672\n","drwxr-xr-x 1 root root    4096 Jun  6 14:21 sample_data\n","-rw-r--r-- 1 root root 5801198 Jun  9 05:18 s-anand.net-Apr-2024.gz\n"]}]},{"cell_type":"markdown","source":["## Uncompress the log file\n","\n","`gzip` is the most popular compression format on the web. It's fast and pretty good. (`xz` is much better but slower.)\n","\n","Since the file has a `.gz` extension, we know it's compressed using `gzip`. We can use `gzip -d FILE.gz` to decompress the file. It'll replace `FILE.gz` with `FILE`.\n","\n","(Compression works the opposite way. `gzip FILE` replaces `FILE` with `FILE.gz`)[link text](https://)"],"metadata":{"id":"tdex0U2h5hhN"}},{"cell_type":"code","source":["# gzip -d is the same as gunzip. They both decompress a GZIP-ed file\n","!gzip -d s-anand.net-Apr-2024.gz"],"metadata":{"id":"t-SHPdPz5K8Z","executionInfo":{"status":"ok","timestamp":1717910335114,"user_tz":-540,"elapsed":6,"user":{"displayName":"Anand S","userId":"10615265647738071129"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Let's list the files and see the size\n","!ls -l"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s4WAFEvj5ISU","executionInfo":{"status":"ok","timestamp":1717910335114,"user_tz":-540,"elapsed":5,"user":{"displayName":"Anand S","userId":"10615265647738071129"}},"outputId":"a54b5460-a975-4ba1-9a13-13207af1fe4a"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["total 50832\n","drwxr-xr-x 1 root root     4096 Jun  6 14:21 sample_data\n","-rw-r--r-- 1 root root 52044491 Jun  9 05:18 s-anand.net-Apr-2024\n"]}]},{"cell_type":"markdown","source":["In this case, a file that was ~5.8MiB became ~52MiB, roughly 10 times larger. Clearly, it's more efficient to store and transport compressed files -- especitally if they're plain text."],"metadata":{"id":"L1t_Zx8J66Bj"}},{"cell_type":"markdown","source":["## Preview the logs\n","\n","To see the first few lines or the last few lines of a text file, use `head` or `tail`*italicized text*"],"metadata":{"id":"jQACYMRn7RDB"}},{"cell_type":"code","source":["# Show the first 5 lines\n","!head -n 5 s-anand.net-Apr-2024"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K7nHrBPK610B","executionInfo":{"status":"ok","timestamp":1717910335503,"user_tz":-540,"elapsed":15,"user":{"displayName":"Anand S","userId":"10615265647738071129"}},"outputId":"c9242ea3-b8c7-48fd-915c-a37f2a40fa7d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["17.241.219.11 - - [31/Mar/2024:07:16:50 -0500] \"GET /hindi/Hari_Puttar_-_A_Comedy_of_Terrors~Meri_Yaadon_Mein_Hai_Tu HTTP/1.1\" 200 2839 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Safari/605.1.15 (Applebot/0.1; +http://www.apple.com/go/applebot)\" www.s-anand.net 192.254.190.216\n","17.241.75.154 - - [31/Mar/2024:07:17:40 -0500] \"GET /hindimp3/~AAN_MILO_SAJNA%3DRANG_RANG_KE_PHOOL_KHILE HTTP/1.1\" 200 2786 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Safari/605.1.15 (Applebot/0.1; +http://www.apple.com/go/applebot)\" www.s-anand.net 192.254.190.216\n","101.44.248.120 - - [31/Mar/2024:07:19:03 -0500] \"GET /hindi/BRAHMCHARI HTTP/1.1\" 200 2757 \"http://www.s-anand.net/hindi/BRAHMCHARI\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\" www.s-anand.net 192.254.190.216\n","17.241.227.200 - - [31/Mar/2024:07:19:31 -0500] \"GET /malayalam/Kaarunyam~Valampiri_Sangil HTTP/1.1\" 200 2749 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Safari/605.1.15 (Applebot/0.1; +http://www.apple.com/go/applebot)\" www.s-anand.net 192.254.190.216\n","37.59.21.100 - - [31/Mar/2024:07:19:41 -0500] \"GET /blog/matching-misspelt-tamil-movie-names/feed/ HTTP/1.1\" 200 1105 \"-\" \"Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.66 Safari/537.36\" www.s-anand.net 192.254.190.216\n"]}]},{"cell_type":"code","source":["# Show the last 5 files\n","!tail -n 5 s-anand.net-Apr-2024"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OYhCSSQ77cFr","executionInfo":{"status":"ok","timestamp":1717910335503,"user_tz":-540,"elapsed":10,"user":{"displayName":"Anand S","userId":"10615265647738071129"}},"outputId":"c0bb94bb-f77f-47ba-f58e-4ca3e9535513"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["47.128.125.180 - - [30/Apr/2024:07:07:47 -0500] \"GET /tamil/Subramaniyapuram HTTP/1.1\" 406 226 \"-\" \"Mozilla/5.0 (compatible; Bytespider; spider-feedback@bytedance.com) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.0.0 Safari/537.36\" www.s-anand.net 192.254.190.216\n","37.59.21.100 - - [30/Apr/2024:07:10:27 -0500] \"GET /blog/bollywood-actress-jigsaw-quiz/feed/ HTTP/1.1\" 200 1072 \"-\" \"Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.66 Safari/537.36\" www.s-anand.net 192.254.190.216\n","40.77.167.48 - - [30/Apr/2024:07:11:10 -0500] \"GET /tamilmp3 HTTP/1.1\" 200 4157 \"-\" \"Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko; compatible; bingbot/2.0; +http://www.bing.com/bingbot.htm) Chrome/116.0.1938.76 Safari/537.36\" www.s-anand.net 192.254.190.216\n","52.167.144.19 - - [30/Apr/2024:07:11:15 -0500] \"GET /malayalam/Ayirathil%20Oruvan HTTP/1.1\" 403 450 \"-\" \"Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko; compatible; bingbot/2.0; +http://www.bing.com/bingbot.htm) Chrome/116.0.1938.76 Safari/537.36\" www.s-anand.net 192.254.190.216\n","37.59.21.100 - - [30/Apr/2024:07:11:31 -0500] \"GET /blog/2003-mumbai-bloggers-meet-photos/feed/ HTTP/1.1\" 200 686 \"-\" \"Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.66 Safari/537.36\" www.s-anand.net 192.254.190.216\n"]}]},{"cell_type":"markdown","source":["Clearly, the data is from around 31 Mar 2024 a bit after 7 am EST (GMT-5) until 30 Apr 2024, a bit after 7 am EST.\n","\n","Each line is an Apache log record. It has a lot of data. Some are clear. For example, taking the last row:\n","\n","- `37.59.21.100` is the IP address that made a request. That's from [OVH](https://www.whois.com/whois/37.59.21.100) - a French cloud provider. Maybe a bot.\n","- `[30/Apr/2024:07:11:31 -0500]` is the time of the request\n","- `\"GET /blog/2003-mumbai-bloggers-meet-photos/feed/ HTTP/1.1\"` is the request made to [this page](https://s-anand.net/blog/2003-mumbai-bloggers-meet-photos/feed/)\n","- `200` is the HTTP reponse status code, indicating that all's well\n","- `686` bytes was the size of the response\n","- `\"Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.66 Safari/537.36\"` is the user agent. That's Chrome 30 -- a really old versio of Chrome on Linux. Very likely a bot."],"metadata":{"id":"CI2ZY2Pl9RyK"}},{"cell_type":"markdown","source":["## Count requests\n","\n","`wc` counts the number of lines, words, and characters in a file. The number of lines is most often used with data."],"metadata":{"id":"2vfLSBNM-xl1"}},{"cell_type":"code","source":["!wc s-anand.net-Apr-2024"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SKyUdGY99Q33","executionInfo":{"status":"ok","timestamp":1717910335886,"user_tz":-540,"elapsed":387,"user":{"displayName":"Anand S","userId":"10615265647738071129"}},"outputId":"b2f3ca0e-841b-407b-ec2d-1de6966199cf"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["  208539  4194545 52044491 s-anand.net-Apr-2024\n"]}]},{"cell_type":"markdown","source":["So, in Apr 2024, there were ~208K requests to the site. Useful to know.\n","\n","I wonder: **Who is sending most of these requests?**\n","\n","Let's extract the IP addresses and count them."],"metadata":{"id":"dL4_oW74_kZL"}},{"cell_type":"markdown","source":["## Extract the `IP` column\n","\n","We'll use `cut` to cut the first column. It has 2 options that we'll use.\n","\n","`--delimiter` is the character that splits fields. In the log file, it's a space. (We'll confirm this shortly.)\n","`--fields` picks the field to cut. We want field 1 (IP address)\n","\n","Let's preview this:"],"metadata":{"id":"m3Ems_5F_4mK"}},{"cell_type":"code","source":["# Preview just the IP addresses from the logs\n","!cut --delimiter \" \" --fields 1 s-anand.net-Apr-2024 | head -n 5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XciAdQzF-5qN","executionInfo":{"status":"ok","timestamp":1717910335886,"user_tz":-540,"elapsed":8,"user":{"displayName":"Anand S","userId":"10615265647738071129"}},"outputId":"857d6209-8b46-4d4f-e0d1-c5081cf31ab6"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["17.241.219.11\n","17.241.75.154\n","101.44.248.120\n","17.241.227.200\n","37.59.21.100\n"]}]},{"cell_type":"markdown","source":["We used the `|` operator. That passes the output to the next command, `head -n 5`, and gives us first 5 lines. This is called **piping** and is the equivalent of calling a function inside another in programming languages."],"metadata":{"id":"Kj8eDP1vAtMR"}},{"cell_type":"markdown","source":["We'll use `sort` to sort these IP addresses. That puts the same IP addresses next to each other."],"metadata":{"id":"wbZDocEDBBLi"}},{"cell_type":"code","source":["# Preview the SORTED IP addresses from the logs\n","!cut --delimiter \" \" --fields 1 s-anand.net-Apr-2024 | sort | head -n 5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wbsrAWFuALJN","executionInfo":{"status":"ok","timestamp":1717910337223,"user_tz":-540,"elapsed":1341,"user":{"displayName":"Anand S","userId":"10615265647738071129"}},"outputId":"64a50508-79e0-40e5-8215-e0cc1b7575c3"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["100.20.65.50\n","100.43.111.139\n","101.100.145.51\n","101.115.156.11\n","101.115.205.68\n"]}]},{"cell_type":"markdown","source":["There are no duplicates there... maybe we need to go a bit further? Let's check the top 25 lines."],"metadata":{"id":"dIj9ZxTqBXHE"}},{"cell_type":"code","source":["# Preview the SORTED IP addresses from the logs\n","!cut --delimiter \" \" --fields 1 s-anand.net-Apr-2024 | sort | head -n 25"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cWZW4XiYBShb","executionInfo":{"status":"ok","timestamp":1717910337743,"user_tz":-540,"elapsed":523,"user":{"displayName":"Anand S","userId":"10615265647738071129"}},"outputId":"48d50ed0-4d5f-42e8-b983-d31054c01fa8"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["100.20.65.50\n","100.43.111.139\n","101.100.145.51\n","101.115.156.11\n","101.115.205.68\n","101.126.25.225\n","101.132.248.41\n","101.166.40.221\n","101.166.6.221\n","101.183.40.167\n","101.185.221.147\n","101.188.225.246\n","101.200.218.166\n","101.201.66.35\n","101.2.187.83\n","101.2.187.83\n","101.2.187.83\n","101.2.187.83\n","101.2.187.83\n","101.2.187.83\n","101.2.187.83\n","101.44.160.158\n","101.44.160.158\n","101.44.160.177\n","101.44.160.177\n"]}]},{"cell_type":"markdown","source":["OK, there are some duplicates. Good to know.\n","\n","We'll use `uniq` to count the unique IP addresses. It has a `--count` option that displays the number of unique values.\n","\n","**NOTE**: `uniq` works ONLY on sorted files. You NEED to `sort` first."],"metadata":{"id":"esY8iaSLBfLw"}},{"cell_type":"code","source":["!cut --delimiter \" \" --fields 1 s-anand.net-Apr-2024 | sort | uniq --count | head -n 25"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z_MyUlCEBdvO","executionInfo":{"status":"ok","timestamp":1717910338508,"user_tz":-540,"elapsed":769,"user":{"displayName":"Anand S","userId":"10615265647738071129"}},"outputId":"641ed49b-3458-4418-b680-5ab057e5d92c"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["      1 100.20.65.50\n","      1 100.43.111.139\n","      1 101.100.145.51\n","      1 101.115.156.11\n","      1 101.115.205.68\n","      1 101.126.25.225\n","      1 101.132.248.41\n","      1 101.166.40.221\n","      1 101.166.6.221\n","      1 101.183.40.167\n","      1 101.185.221.147\n","      1 101.188.225.246\n","      1 101.200.218.166\n","      1 101.201.66.35\n","      7 101.2.187.83\n","      2 101.44.160.158\n","      2 101.44.160.177\n","      2 101.44.160.189\n","      3 101.44.160.20\n","      2 101.44.160.41\n","      1 101.44.161.208\n","      1 101.44.161.71\n","      3 101.44.161.77\n","      2 101.44.161.93\n","      2 101.44.162.166\n"]}]},{"cell_type":"markdown","source":["That's useful. [101.2.187.83](https://www.whois.com/whois/101.2.187.83) from Colombo visited 7 times.\n","\n","But I'd like to know who visited the MOST. So let's `sort` it further.\n","\n","`sort` has an option `--key 1n` that sorts by field `1` -- the count of IP addresses in this case. The `n` indicates that it's a numeric sort (so 11 appears AFTER 2).\n","\n","Also, we'll use `tail` instead of `head` to get the highest entries."],"metadata":{"id":"EuLynbF3CB0d"}},{"cell_type":"code","source":["# Show the top 5 IP addresses by visits\n","!cut --delimiter \" \" --fields 1 s-anand.net-Apr-2024 | sort | uniq --count | sort --key 1n | tail -n 5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q0zwaHQrBmKR","executionInfo":{"status":"ok","timestamp":1717910339175,"user_tz":-540,"elapsed":670,"user":{"displayName":"Anand S","userId":"10615265647738071129"}},"outputId":"c96bda9c-b480-4c0d-f8e3-3e45d6d74d37"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["   2560 66.249.70.6\n","   3010 148.251.241.12\n","   4245 35.86.164.73\n","   7800 37.59.21.100\n"," 101255 136.243.228.193\n"]}]},{"cell_type":"markdown","source":["WOW! [136.243.228.193](https://www.whois.com/whois/136.243.228.193) from Dataforseo, Ukraine, sent roughly HALF of ALL the requests!\n","\n","I wonder if we can figure out what User Agent they send. Is it something that identifies itself as a bot of some kind?"],"metadata":{"id":"ttsytVqlDUX3"}},{"cell_type":"markdown","source":["## Find lines matching an IP\n","\n","`grep` searches for text in files. It uses [Regular Expressions](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_expressions) which are a powerful set of wildcards.\n","\n","ðŸ’¡ TIP: You **MUST** learn regular expressions. They're very helpful.\n","\n","Here, we'll search for all lines BEGINNING with 136.243.228.193 and having a space after that. That's `\"^136.243.228.193 \"`. The `^` at the beginning matches the start of a line."],"metadata":{"id":"5V1C_N3bDvUt"}},{"cell_type":"code","source":["# Preview lines that begin with 136.243.228.193\n","!grep \"^136.243.228.193 \" s-anand.net-Apr-2024 | head -n 5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LssC6LwJCcA2","executionInfo":{"status":"ok","timestamp":1717910339175,"user_tz":-540,"elapsed":7,"user":{"displayName":"Anand S","userId":"10615265647738071129"}},"outputId":"b7f47966-81bd-4345-85ed-f91787d7fdf3"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["136.243.228.193 - - [31/Mar/2024:11:27:43 -0500] \"GET /kannadamp3 HTTP/1.1\" 200 4162 \"-\" \"Mozilla/5.0 (compatible; DataForSeoBot/1.0; +https://dataforseo.com/dataforseo-bot)\" www.s-anand.net 192.254.190.216\n","136.243.228.193 - - [31/Mar/2024:11:31:07 -0500] \"GET /kannadamp3 HTTP/1.1\" 200 4162 \"-\" \"Mozilla/5.0 (compatible; DataForSeoBot/1.0; +https://dataforseo.com/dataforseo-bot)\" www.s-anand.net 192.254.190.216\n","136.243.228.193 - - [03/Apr/2024:17:46:42 -0500] \"GET /robots.txt HTTP/1.1\" 200 195 \"-\" \"Mozilla/5.0 (compatible; DataForSeoBot/1.0; +https://dataforseo.com/dataforseo-bot)\" www.s-anand.net 192.254.190.216\n","136.243.228.193 - - [06/Apr/2024:02:58:43 -0500] \"GET /Statistically_improbable_phrases.html HTTP/1.1\" 301 - \"-\" \"Mozilla/5.0 (compatible; DataForSeoBot/1.0; +https://dataforseo.com/dataforseo-bot)\" www.s-anand.net 192.254.190.216\n","136.243.228.193 - - [08/Apr/2024:22:38:25 -0500] \"GET /robots.txt HTTP/1.1\" 200 195 \"-\" \"Mozilla/5.0 (compatible; DataForSeoBot/1.0; +https://dataforseo.com/dataforseo-bot)\" www.s-anand.net 192.254.190.216\n"]}]},{"cell_type":"markdown","source":["These requests have clearly identified themselves as `DataForSeoBot/1.0`, which is helpful. It also seems to be crawling `robots.txt` to check if it's allowed to crawl the site, which is polite."],"metadata":{"id":"BYbLhp2DEcR-"}},{"cell_type":"markdown","source":["Let's look at the second IP address: [37.59.21.100](https://www.whois.com/whois/37.59.21.100). That seems to be from OVH, a French cloud hosting provider. Is that a bot, too?"],"metadata":{"id":"zzHTYPoPE3-e"}},{"cell_type":"code","source":["# Preview lines that begin with 37.59.21.100\n","!grep \"^37.59.21.100 \" s-anand.net-Apr-2024 | head -n 5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"chaknqW2EYwc","executionInfo":{"status":"ok","timestamp":1717910339689,"user_tz":-540,"elapsed":517,"user":{"displayName":"Anand S","userId":"10615265647738071129"}},"outputId":"7adfecb9-93eb-4edf-b926-f60ae84a8c57"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["37.59.21.100 - - [31/Mar/2024:07:19:41 -0500] \"GET /blog/matching-misspelt-tamil-movie-names/feed/ HTTP/1.1\" 200 1105 \"-\" \"Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.66 Safari/537.36\" www.s-anand.net 192.254.190.216\n","37.59.21.100 - - [31/Mar/2024:07:19:53 -0500] \"GET /blog/hindi-songs-online/feed/ HTTP/1.1\" 200 1382 \"-\" \"Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.66 Safari/537.36\" www.s-anand.net 192.254.190.216\n","37.59.21.100 - - [31/Mar/2024:07:24:26 -0500] \"GET /blog/check-your-mobile-phones-serial-number/feed/ HTTP/1.1\" 200 1572 \"-\" \"Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.66 Safari/537.36\" www.s-anand.net 192.254.190.216\n","37.59.21.100 - - [31/Mar/2024:07:33:10 -0500] \"GET /blog/classical-ilayaraja-2/feed/ HTTP/1.1\" 200 1286 \"-\" \"Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.66 Safari/537.36\" www.s-anand.net 192.254.190.216\n","37.59.21.100 - - [31/Mar/2024:07:36:33 -0500] \"GET /blog/correlating-subjects/feed/ HTTP/1.1\" 200 2257 \"-\" \"Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.66 Safari/537.36\" www.s-anand.net 192.254.190.216\n"]}]},{"cell_type":"markdown","source":["Looking at the user agent, `Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.66 Safari/537.36`, it looks like Chrome 30 -- a very old version.\n","\n","Personally, I believe it's more likely to be a bot than a French human so interested in my website that they made over 250 requests *every day*."],"metadata":{"id":"dP5kOucbFXN_"}},{"cell_type":"markdown","source":["## Find bots\n","\n","But, I'm curious. What are the user agents that DO identify themselves as bots? Let's use `grep` to find all words that match bot.\n","\n","`grep --only-matching` will show only the matches, not the entire line.\n","\n","The regular expression `'\\S*bot\\S*'` (which ChatGPT generated) finds all words that have bot.\n","\n","- `\\S` matches non-space characters\n","- `\\S*` matches 0 or more non-space characters"],"metadata":{"id":"SBbna3VYFzD5"}},{"cell_type":"code","source":["# Find all words with `bot` in it\n","!grep --only-matching '\\b\\w*bot\\w*\\b' s-anand.net-Apr-2024 | head"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WRg6_L21FFh6","executionInfo":{"status":"ok","timestamp":1717910339689,"user_tz":-540,"elapsed":5,"user":{"displayName":"Anand S","userId":"10615265647738071129"}},"outputId":"9f9877fa-b367-40ac-d307-898b226992a7"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Applebot\n","applebot\n","Applebot\n","applebot\n","Applebot\n","applebot\n","Applebot\n","applebot\n","Applebot\n","applebot\n"]}]},{"cell_type":"code","source":["# Count frequency of all words with `bot` in it and show the top 10\n","!grep --only-matching '\\S*bot\\S*' s-anand.net-Apr-2024 | sort | uniq --count | sort --key 1n | tail"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zZIy6a_gGGIj","executionInfo":{"status":"ok","timestamp":1717910346400,"user_tz":-540,"elapsed":6714,"user":{"displayName":"Anand S","userId":"10615265647738071129"}},"outputId":"d9f9240b-c137-435a-a39e-a87d3f9b34e4"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["   4134 PetalBot;+https://webmaster.petalsearch.com/site/petalbot)\"\n","   4307 /robots.txt\n","   5664 bingbot/2.0;\n","   5664 +http://www.bing.com/bingbot.htm)\n","   8771 +claudebot@anthropic.com)\"\n","   8827 +http://www.google.com/bot.html)\"\n","   8830 Googlebot/2.1;\n","  13798 (Applebot/0.1;\n","  13798 +http://www.apple.com/go/applebot)\"\n"," 101262 +https://dataforseo.com/dataforseo-bot)\"\n"]}]},{"cell_type":"markdown","source":["That gives me a rough sense of who's crawling my site.\n","\n","1. [DataForSEO](https://dataforseo.com/)\n","2. [Apple](https://www.apple.com/)\n","3. [Google](https://www.google.com/)\n","4. [Anthropic](https://www.anthropic.com/)\n","5. [Bing](https://www.bing.com/)\n","6. [PetalBot](https://aspiegel.com/petalbot)"],"metadata":{"id":"4s1sbzbFH3xI"}},{"cell_type":"markdown","source":["## Convert logs to CSV\n","\n","This file is *almost* a CSV file separated by spaces instead of commas.\n","\n","The main problem is the date. Instead of `[31/Mar/2024:11:27:43 -0500]` it should have been `\"31/Mar/2024:11:27:43 -0500\"`\n","\n","We'll use `sed` (stream editor) to replace the characters. `sed` is like `grep` but lets you replace, not just search.\n","\n","(Actually, `sed` can do a lot more. It's a full-fledged editor. You can insert, delete, edit, etc. programmatically. In fact, `sed` has truly remarkable features that this paragraph is too small to contain.)\n","\n","The regular expression we will use is `\\[\\([^]]*\\)\\]`. The way this works is:\n","\n","- `\\[`: Match the opening square bracket.\n","- `\\([^]]*\\)`: Capture everything inside the square brackets (non-greedy match for any character except `]`).\n","- `\\]`: Match the closing square bracket.\n","\n","BTW, I didn't create this. [ChatGPT did](https://chatgpt.com/share/7f14e9d2-15ec-4562-b263-61547d2230f3).\n","\n","`sed \"s/abc/xyz/\" FILE` replaces `abc` with `xyz` in the file. We can use the regular expression above for the search and `\"\\1\"` for the value -- it inserts captured group enclosed in double quotes."],"metadata":{"id":"7K_UZOO9JaJY"}},{"cell_type":"code","source":["# Replace [datetime] etc. with \"datetime\" and save as log.csv\n","!sed 's/\\[\\([^]]*\\)\\]/\"\\1\"/' s-anand.net-Apr-2024 > log.csv"],"metadata":{"id":"srB3a7R2Gpah","executionInfo":{"status":"ok","timestamp":1717910348121,"user_tz":-540,"elapsed":1739,"user":{"displayName":"Anand S","userId":"10615265647738071129"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# We should now have a log.csv that's roughly the same size as the original file.\n","!ls -l"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PjZPn7sJXZPy","executionInfo":{"status":"ok","timestamp":1717910348121,"user_tz":-540,"elapsed":6,"user":{"displayName":"Anand S","userId":"10615265647738071129"}},"outputId":"26207466-7330-4edd-a70d-939e1e214b65"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["total 101660\n","-rw-r--r-- 1 root root 52044491 Jun  9 05:19 log.csv\n","drwxr-xr-x 1 root root     4096 Jun  6 14:21 sample_data\n","-rw-r--r-- 1 root root 52044491 Jun  9 05:18 s-anand.net-Apr-2024\n"]}]},{"cell_type":"markdown","source":["You can download this `log.csv` and open it in Excel as a CSV file with space as the delimiter.\n","\n","But when I did that, I faced another problem. Some of the lines had extra columns.\n","\n","That's because the \"User Agent\" values sometimes contain a quote. CSV files are supposed to escape quotes with `\"\"` -- two double quotes. But Apache uses `\\\"` instead.\n","\n","I'll leave it as an exercise for you to fix that."],"metadata":{"id":"va8shF_AZvcC"}},{"cell_type":"markdown","source":["## More commands\n","\n","We've covered the commands most often used to process data before analysis.\n","\n","Here are a few more that you'll find useful.\n","\n","- `cat` concatenates multiple files. You can join multiple log files with this, for example\n","- `awk` is almost a full-fledged programming interface. It's often used for summing up values\n","- `less` lets you open and read files, scrolling through it\n","\n","You can read the book [Data Science at the Command Line](https://jeroenjanssens.com/dsatcl/) for more tools and examples."],"metadata":{"id":"AZxDkeU1Za7Z"}}]}