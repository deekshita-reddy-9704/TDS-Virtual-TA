['git', 'clone', '-q', '--single-branch', '-b', 'main', 'https://github.com/MuthuAnushree/TDS-Project-2.git', '/root/.local/share/tds-sep-24-project-2/23f2000295']





------------------------------------------------------------------------

['uv', 'run', '/root/.local/share/tds-sep-24-project-2/23f2000295/autolysis.py', '/root/.local/share/tds-sep-24-project-2/datasets/goodreads.csv']

Data loaded successfully! Shape: (10000, 23)
First few rows of the data:
   book_id  ...                                    small_image_url
0        1  ...  https://images.gr-assets.com/books/1447303603s...
1        2  ...  https://images.gr-assets.com/books/1474154022s...
2        3  ...  https://images.gr-assets.com/books/1361039443s...
3        4  ...  https://images.gr-assets.com/books/1361975680s...
4        5  ...  https://images.gr-assets.com/books/1490528560s...

[5 rows x 23 columns]

--- Cleaning Data ---

Missing Values per Column:
book_id                         0
goodreads_book_id               0
best_book_id                    0
work_id                         0
books_count                     0
isbn                          700
isbn13                        585
authors                         0
original_publication_year      21
original_title                585
title                           0
language_code                1084
average_rating                  0
ratings_count                   0
work_ratings_count              0
work_text_reviews_count         0
ratings_1                       0
ratings_2                       0
ratings_3                       0
ratings_4                       0
ratings_5                       0
image_url                       0
small_image_url                 0
dtype: int64

Removed 0 duplicate rows.

Standardized Column Names:
['book_id', 'goodreads_book_id', 'best_book_id', 'work_id', 'books_count', 'isbn', 'isbn13', 'authors', 'original_publication_year', 'original_title', 'title', 'language_code', 'average_rating', 'ratings_count', 'work_ratings_count', 'work_text_reviews_count', 'ratings_1', 'ratings_2', 'ratings_3', 'ratings_4', 'ratings_5', 'image_url', 'small_image_url']
Skipped column 'isbn' as it contains non-numeric values.
Skipped column 'authors' as it contains non-numeric values.
Skipped column 'original_title' as it contains non-numeric values.
Skipped column 'title' as it contains non-numeric values.
Skipped column 'language_code' as it contains non-numeric values.
Skipped column 'image_url' as it contains non-numeric values.
Skipped column 'small_image_url' as it contains non-numeric values.

Data cleaned successfully!

--- Cleaned Data Info ---
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 10000 entries, 0 to 9999
Data columns (total 23 columns):
 #   Column                     Non-Null Count  Dtype  
---  ------                     --------------  -----  
 0   book_id                    10000 non-null  int64  
 1   goodreads_book_id          10000 non-null  int64  
 2   best_book_id               10000 non-null  int64  
 3   work_id                    10000 non-null  int64  
 4   books_count                10000 non-null  int64  
 5   isbn                       10000 non-null  object 
 6   isbn13                     10000 non-null  float64
 7   authors                    10000 non-null  object 
 8   original_publication_year  10000 non-null  float64
 9   original_title             10000 non-null  object 
 10  title                      10000 non-null  object 
 11  language_code              10000 non-null  object 
 12  average_rating             10000 non-null  float64
 13  ratings_count              10000 non-null  int64  
 14  work_ratings_count         10000 non-null  int64  
 15  work_text_reviews_count    10000 non-null  int64  
 16  ratings_1                  10000 non-null  int64  
 17  ratings_2                  10000 non-null  int64  
 18  ratings_3                  10000 non-null  int64  
 19  ratings_4                  10000 non-null  int64  
 20  ratings_5                  10000 non-null  int64  
 21  image_url                  10000 non-null  object 
 22  small_image_url            10000 non-null  object 
dtypes: float64(3), int64(13), object(7)
memory usage: 1.8+ MB
None

Sample of Cleaned Data:
   book_id  ...                                    small_image_url
0        1  ...  https://images.gr-assets.com/books/1447303603s...
1        2  ...  https://images.gr-assets.com/books/1474154022s...
2        3  ...  https://images.gr-assets.com/books/1361039443s...
3        4  ...  https://images.gr-assets.com/books/1361975680s...
4        5  ...  https://images.gr-assets.com/books/1490528560s...

[5 rows x 23 columns]

--- Generic Analysis ---

Summary Statistics:
            book_id  ...                                    small_image_url
count   10000.00000  ...                                              10000
unique          NaN  ...                                               6669
top             NaN  ...  https://s.gr-assets.com/assets/nophoto/book/50...
freq            NaN  ...                                               3332
mean     5000.50000  ...                                                NaN
std      2886.89568  ...                                                NaN
min         1.00000  ...                                                NaN
25%      2500.75000  ...                                                NaN
50%      5000.50000  ...                                                NaN
75%      7500.25000  ...                                                NaN
max     10000.00000  ...                                                NaN

[11 rows x 23 columns]
Error from AI proxy: 401, {
  "message": "Bearer None is invalid: JWSInvalid: Invalid Compact JWS"
}
Error generating code from LLM.
Error executing code: invalid syntax (<string>, line 1)


Reading inline script metadata from `/root/.local/share/tds-sep-24-project-2/23f2000295/autolysis.py`
Installed 26 packages in 81ms
/root/.local/share/tds-sep-24-project-2/23f2000295/autolysis.py:80: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  data = data.fillna(method='ffill').fillna(method='bfill')  # Forward and backward fill


------------------------------------------------------------------------

